{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# The Last Samurai's Dinner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Selecting Data\n",
    "\n",
    "Let's read the CSV files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Nec. 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "ainf = pd.read_csv('air_store_info.csv')\n",
    "hinf = pd.read_csv('hpg_store_info.csv')\n",
    "idrel = pd.read_csv('store_id_relation.csv')\n",
    "\n",
    "ares = pd.read_csv('air_reserve.csv')\n",
    "avis = pd.read_csv('air_visit_data.csv')\n",
    "hres = pd.read_csv('hpg_reserve.csv')\n",
    "date_info = pd.read_csv('date_info.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sample_submission = sub.copy()\n",
    "\n",
    "idrel.set_index('hpg_store_id', 'air_store_id')\n",
    "di = idrel.set_index('hpg_store_id').T.to_dict('list')\n",
    "dictionary = {}\n",
    "for key in di:\n",
    "    dictionary[key]=di[key][0]\n",
    "\n",
    "hinf[\"hpg_store_id\"].replace(dictionary, inplace=True)\n",
    "hres[\"hpg_store_id\"].replace(dictionary, inplace=True)\n",
    "ainf.rename(columns={'air_store_id': 'store_id','air_area_name': 'area_name', 'air_genre_name': 'genre_name'}, inplace=True)\n",
    "hinf.rename(columns={'hpg_store_id': 'store_id','hpg_area_name': 'area_name', 'hpg_genre_name': 'genre_name'}, inplace=True)\n",
    "hres.rename(columns={'hpg_store_id': 'store_id'}, inplace=True)\n",
    "ares.rename(columns={'air_store_id': 'store_id'}, inplace=True)\n",
    "avis.rename(columns={'air_store_id': 'store_id', 'visit_date': 'vis_date'}, inplace=True)\n",
    "\n",
    "stsinf = pd.concat([ainf, hinf])\n",
    "res = pd.concat([ares, hres])\n",
    "stsinf = stsinf.drop_duplicates(subset=['store_id'], keep='first')\n",
    "res = res.drop_duplicates(subset=['store_id'], keep='first')\n",
    "stsinf = stsinf.set_index([list(range(len(stsinf)))])\n",
    "res = res.set_index([list(range(len(res)))])\n",
    "\n",
    "stsinf['prefecture'] = stsinf['area_name'].apply(lambda x: x.split('-')[0])\n",
    "stsinf['prefecture'] = stsinf['prefecture'].apply(lambda x: x.split(' ')[0])\n",
    "stsinf['prefecture'].replace('None', np.nan, inplace=True)\n",
    "cleanup_nums = {\"prefecture\":     {\"Tōkyō\": 1, \"Ōsaka\": 2, \"Osaka\": 2, \"Fukuoka\": 3, \"Hyōgo\": 4, \"Hokkaidō\": 5, \"Hiroshima\": 6, \"Shizuoka\": 7, \"Niigata\": 8, \"Miyagi\": 9, \"Kanagawa\": 10, \"Saitama\": 11},\n",
    "                \"genre_name\": {\"Japanese style\": 1, \"Japanese food in general\": 1, \"Japanese food\": 1, \"Japanese cuisine/Kaiseki\": 1,\n",
    "                                  \"Shabu-shabu/Sukiyaki\": 1, \"Okonomiyaki/Monja/Teppanyaki\": 1, \"Udon/Soba\":1, \"Izakaya\": 1,\n",
    "                               \"Seafood\": 1, \"Sushi\": 1, \"Grilled meat\": 1,\n",
    "                              \"Cafe/Sweets\": 2, \"Sweets\": 2, \"Cafe\": 2,\n",
    "                              \"Dining bar\": 3, \"Bar/Cocktail\": 3, \"Karaoke\": 3, \"Party\": 3, \"Amusement bar\": 3, \"Karaoke/Party\": 3,\n",
    "                              \"International cuisine\": 4, \"Italian\": 4, \"Spain Bar/Italian Bar\": 4, \"Italian/French\": 4, \"French\": 4, \"Bistro\": 4,\n",
    "                               \"Spain/Mediterranean cuisine\": 4, \"Steak/Hamburger/Curry\": 4, \"Western food\": 4, \"Pasta/Pizza\": 4,\n",
    "                              \"Chinese general\": 5, \"Korean cuisine\": 5, \"Yakiniku/Korean food\": 5, \"Thai/Vietnamese food\": 5,\n",
    "                               \"Cantonese food\": 5, \"Sichuan food\": 5, \"Asian\": 5,\n",
    "                              \"Dim Sum/Dumplings\": 5, \"Shanghai food\": 5, \"Taiwanese/Hong Kong cuisine\": 5,\n",
    "                              \"Other\": 6,\n",
    "                               \"Creation\": 7, \"Creative Japanese food\": 7, \"Creative cuisine\": 7},\n",
    "               \"day_of_week\": {\"Monday\": 1, \"Tuesday\": 2, \"Wednesday\": 3, \"Thursday\": 4, \"Friday\": 5, \"Saturday\": 6, \"Sunday\": 7}}\n",
    "stsinf.replace(cleanup_nums, inplace=True)\n",
    "stsinf = stsinf.drop('area_name', 1)\n",
    "stsinf['prefecture'] = stsinf['prefecture'].fillna(random.choice(stsinf['prefecture'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stsinf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while stsinf.prefecture.isnull().sum() > 0:\n",
    "    index = stsinf['prefecture'].index[stsinf['prefecture'].apply(np.isnan)]\n",
    "    stsinf.loc[np.sqrt((stsinf.longitude.sub(float(stsinf.loc[stsinf.prefecture.isnull(),'longitude'][:1]))).pow(2)\n",
    "                                         +(stsinf.latitude.sub(float(stsinf.loc[stsinf.prefecture.isnull(),'latitude'][:1]))).pow(2)+1e-10*stsinf.prefecture)\n",
    "                                       .idxmin()].prefecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stsinf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Nec. 2\n",
    "\n",
    "\n",
    "stsinf = stsinf.drop('longitude', 1)\n",
    "stsinf = stsinf.drop('latitude', 1)\n",
    "\n",
    "def hr_func(ts):\n",
    "    return ts.hour\n",
    "\n",
    "\n",
    "res['visit_datetime'] = res['visit_datetime'].apply(lambda x : pd.to_datetime(str(x)))\n",
    "res['vis_date'] = res['visit_datetime'].dt.date\n",
    "res['vis_hour'] = res['visit_datetime'].dt.time\n",
    "\n",
    "res['reserve_datetime'] = res['reserve_datetime'].apply(lambda x : pd.to_datetime(str(x)))\n",
    "res['res_date'] = res['reserve_datetime'].dt.date\n",
    "res['res_hour'] = res['reserve_datetime'].dt.time\n",
    "\n",
    "avis['vis_date'] = avis['vis_date'].apply(lambda x : pd.to_datetime(str(x)))\n",
    "avis['vis_date'] = avis['vis_date'].dt.date\n",
    "res['vis_h'] = res['vis_hour'].apply(hr_func)\n",
    "res['res_h'] = res['res_hour'].apply(hr_func)\n",
    "res.drop(['visit_datetime', 'reserve_datetime', 'vis_hour', 'res_hour'], axis=1, inplace=True)\n",
    "date_info['vis_date'] = date_info['calendar_date'].apply(lambda x : pd.to_datetime(str(x)))\n",
    "date_info.replace(cleanup_nums, inplace=True)\n",
    "date_info['vis_date'] = date_info['vis_date'].dt.date\n",
    "date_info = date_info.drop('calendar_date', 1)\n",
    "reserve = res.merge(avis, on=['store_id', 'vis_date'], how='outer')\n",
    "reserve = reserve.merge(date_info, on=['vis_date'], how='outer')\n",
    "df = reserve.merge(stsinf, on=['store_id'], how='outer')\n",
    "df.visitors.fillna(value=df['reserve_visitors'].groupby([df['store_id'],df['vis_date']]).transform('sum'), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[np.isfinite(df['visitors'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nec. 2\n",
    "\n",
    "df[\"genre_name\"].fillna(random.choice(df[df['genre_name'] != np.nan][\"genre_name\"]).astype(float), inplace =True)\n",
    "df[\"prefecture\"].fillna(random.choice(df[df['prefecture'] != np.nan][\"prefecture\"]), inplace =True)\n",
    "df = df.dropna(subset = ['store_id'])\n",
    "\n",
    "sub['store_id'] = sub['id'].apply(lambda x: x.split('_')[0]+'_'+x.split('_')[1])\n",
    "sub['vis_date'] = sub['id'].apply(lambda x: x.split('_')[2])\n",
    "sub['vis_date'] = sub['vis_date'].apply(lambda x : pd.to_datetime(str(x)))\n",
    "sub['vis_date'] = sub['vis_date'].dt.date\n",
    "sub = sub.merge(stsinf, on=['store_id'], how='inner')\n",
    "sub = sub[['store_id','vis_date','genre_name','prefecture']]\n",
    "sub = sub.merge(date_info, on='vis_date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualisations\n",
    "%matplotlib inline\n",
    "mpl.style.use( 'ggplot' )\n",
    "sns.set_style( 'white' )\n",
    "pylab.rcParams[ 'figure.figsize' ] = 8 , 6\n",
    "\n",
    "def plot_correlation_map( df ):\n",
    "    corr = df.corr()\n",
    "    _ , ax = plt.subplots( figsize =( 12 , 10 ) )\n",
    "    cmap = sns.diverging_palette( 220 , 10 , as_cmap = True )\n",
    "    _ = sns.heatmap(\n",
    "        corr, \n",
    "        cmap = cmap,\n",
    "        square=True, \n",
    "        cbar_kws={ 'shrink' : .9 }, \n",
    "        ax=ax, \n",
    "        annot = True, \n",
    "        annot_kws = { 'fontsize' : 12 }\n",
    "    )\n",
    "\n",
    "plot_correlation_map( df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot visitors number by genre\n",
    "def plot_categories( df , cat , target , **kwargs ):\n",
    "    row = kwargs.get( 'row' , None )\n",
    "    col = kwargs.get( 'col' , None )\n",
    "    facet = sns.FacetGrid( df , row = row , col = col )\n",
    "    facet.map( sns.barplot , cat , target )\n",
    "    facet.add_legend()\n",
    "\n",
    "plot_categories( df , cat = 'genre_name' , target = 'visitors' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Nec. 4\n",
    "\n",
    "\n",
    "# Create all datasets that are necessary to train, validate and test models\n",
    "# Modelling Algorithms\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier , GradientBoostingClassifier\n",
    "\n",
    "# Modelling Helpers\n",
    "from sklearn.preprocessing import Imputer , Normalizer , scale\n",
    "from sklearn.cross_validation import train_test_split , StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "train_valid_X = df[['vis_date','genre_name', 'prefecture', 'day_of_week', 'holiday_flg']]\n",
    "\n",
    "from datetime import datetime\n",
    "start_date = train_valid_X['vis_date'].min()\n",
    "train_valid_X['vis_date'] = train_valid_X['vis_date'] - start_date\n",
    "train_valid_X['vis_date'] = train_valid_X['vis_date'].dt.days\n",
    "\n",
    "train_valid_y = df['visitors']\n",
    "test_X = sub\n",
    "test_X = test_X[['vis_date','genre_name', 'prefecture', 'day_of_week', 'holiday_flg']]\n",
    "test_X['vis_date'] = test_X['vis_date'] - start_date\n",
    "test_X['vis_date'] = test_X['vis_date'].dt.days\n",
    "\n",
    "train_X , valid_X , train_y , valid_y = train_test_split( train_valid_X , train_valid_y , train_size = .7 )\n",
    "\n",
    "print (train_X.shape , valid_X.shape , train_y.shape , valid_y.shape , test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_model_var_imp( model , X , y ):\n",
    "    imp = pd.DataFrame( \n",
    "        model.feature_importances_  , \n",
    "        columns = [ 'Importance' ] , \n",
    "        index = X.columns \n",
    "    )\n",
    "    imp = imp.sort_values( [ 'Importance' ] , ascending = True )\n",
    "    imp[ : 10 ].plot( kind = 'barh' )\n",
    "    print (model.score( X , y ))\n",
    "\n",
    "def plot_variable_importance( X , y ):\n",
    "    tree = DecisionTreeClassifier( random_state = 99 )\n",
    "    tree.fit( X , y )\n",
    "    plot_model_var_imp( tree , X , y )\n",
    "    \n",
    "plot_variable_importance(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit( train_X , train_y )\n",
    "\n",
    "# Score the model\n",
    "print (model.score( train_X , train_y ) , model.score( valid_X , valid_y ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_Y = model.predict( test_X )\n",
    "vis_id = sample_submission.id\n",
    "test = pd.DataFrame( { 'id': vis_id , 'visitors': test_Y } )\n",
    "test.shape\n",
    "test.head()\n",
    "test.to_csv( 'Recruit_Sub.csv' , index = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
